# ai/ml_api/ml/pipeline/train_model_pmv.py
# Zhang 2020, Schiavon 2025 ê¸°ë°˜ PMV ëª¨ë¸ í•™ìŠµ

import os
import math
import random
import joblib
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# LightGBM & Scikit-learn
from lightgbm import LGBMRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split, learning_curve, cross_val_score

from optuna.samplers import TPESampler

random.seed(42)
np.random.seed(42)

try:
    import optuna
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False
    print("âš ï¸ Optunaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")

# --- 1. í™˜ê²½ ì„¤ì • ---
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['axes.unicode_minus'] = False

# [ê¸°ì¤€í‘œ]
DEFAULT_MET = 1.5  # í™œë™ëŸ‰ (ê±·ê¸°/í†µí•™ ê¸°ì¤€)


# --- 2. PMV ê³„ì‚° í•¨ìˆ˜ ì •ì˜ ---
def calculate_pmv_standard(ta, tr, vel, rh, met, clo, wme=0):
    """í‘œì¤€ ISO 7730 PMV ê³„ì‚°ì‹ (Overflow ë°©ì§€ ì ìš©)"""
    try:
        # 1. ì…ë ¥ê°’ ë°©ì–´ ë¡œì§ (ê·¹ë‹¨ì  ê°’ ë³´ì •)
        if ta < -50 or ta > 50: return 999  # ì ˆëŒ€ì ì¸ ì˜¨ë„ ë²”ìœ„ ì´ˆê³¼
        if vel < 0: vel = 0.1
        if rh < 0: rh = 0

        try:
            pa = rh * 10 * math.exp(16.6536 - 4030.183 / (ta + 235))
        except Exception:
            return 999  # ì—ëŸ¬ ë°œìƒ ì‹œ 999 ë¦¬í„´

        icl = 0.155 * clo
        m = met * 58.15
        w = wme * 58.15
        mw = m - w
        if icl <= 0.078:
            fcl = 1 + 1.29 * icl
        else:
            fcl = 1.05 + 0.645 * icl

        # ì—´í‰í˜• ë°˜ë³µ ê³„ì‚°
        tcl = ta
        for _ in range(30):
            hc = 12.1 * math.sqrt(vel)
            if hc < 2.38 * abs(tcl - ta) ** 0.25: hc = 2.38 * abs(tcl - ta) ** 0.25

            # [í•µì‹¬ ìˆ˜ì •] ê³„ì‚° í­ë°œ(Overflow) ê°ì§€ êµ¬ê°„ì„ tryë¡œ ê°ì‹¸ê¸°
            tcl_new = 35.7 - 0.028 * mw - icl * (
                    3.96 * 10 ** -8 * fcl * ((tcl + 273) ** 4 - (tr + 273) ** 4) + fcl * hc * (tcl - ta))

            tcl = 0.8 * tcl + 0.2 * tcl_new

        # PMV ìµœì¢… ì‚°ì¶œ

        ts = 0.303 * math.exp(-0.036 * m) + 0.028
        pmv = ts * (mw - 3.05 * 0.001 * (5733 - 6.99 * mw - pa) - 0.42 * (mw - 58.15)
                    - 1.7 * 10 ** -5 * m * (5867 - pa) - 0.0014 * m * (34 - ta)
                    - 3.96 * 10 ** -8 * fcl * ((tcl + 273) ** 4 - (tr + 273) ** 4) - fcl * hc * (tcl - ta))


        if abs(pmv) > 10:
            return 999

        return pmv

    except Exception as e:
        # ìˆ˜í•™ì  ê³„ì‚° ì—ëŸ¬(Overflow, DivZero ë“±) ë°œìƒ ì‹œ ë¬´ì¡°ê±´ 999 ë°˜í™˜
        return 999


def get_corrected_pmv(raw_pmv, vel):
    """ë…¼ë¬¸ ê¸°ë°˜ PMV í¸í–¥ ë³´ì • (Zhang 2020, Schiavon 2025)"""
    if raw_pmv == 999: return 999  # ì—ëŸ¬ ê°’ì€ ê·¸ëŒ€ë¡œ ì „ë‹¬

    corrected_pmv = raw_pmv
    # 1. ì¤‘ë¦½ì—ì„œ ë©€ì–´ì§ˆìˆ˜ë¡ ê³¼ëŒ€í‰ê°€ ê²½í–¥ ì™„í™” (Damping)
    if abs(raw_pmv) > 0.5:
        corrected_pmv = raw_pmv * 0.8
    # 2. ê°•í’ ì‹œ ì¶”ìœ„ ê³¼ëŒ€í‰ê°€ ë³´ì •
    if vel > 0.2 and raw_pmv < 0:
        corrected_pmv += 0.2
    return corrected_pmv


# --- 3. ë°ì´í„° ìƒì„± (Data Generation) ---
print("ğŸ§ª [Level 5] ISO 7730 + ë…¼ë¬¸ ë³´ì • ê¸°ë°˜ ë°ì´í„° 30ë§Œê°œ ìƒì„± ì¤‘...")
data = []

def get_clo_from_warmth(w):
    # ì •ìˆ˜ êµ¬ê°„ë³„ ì„ í˜• ë³´ê°„ (Linear Interpolation)
    if w <= 1: return 0.15
    if w <= 2: return 0.15 + (0.4 - 0.15) * (w - 1)  # 1~2 ì‚¬ì´
    if w <= 3: return 0.4 + (0.7 - 0.4) * (w - 2)    # 2~3 ì‚¬ì´
    if w <= 4: return 0.7 + (1.5 - 0.7) * (w - 3)    # 3~4 ì‚¬ì´
    return 1.5 + (2.8 - 1.5) * (w - 4)               # 4~5 ì‚¬ì´

for _ in range(300000):
    # ë‚ ì”¨
    temp = random.uniform(-20, 35)
    humidity = random.uniform(0, 95)
    wind_speed = random.uniform(0.1, 10)

    # ì¼êµì°¨ (API temp_min/max ì‹œë®¬ë ˆì´ì…˜)
    if 10 <= temp <= 25:
        temp_diff = random.uniform(5, 15)
    else:
        temp_diff = random.uniform(2, 8)

    # ì†Œì¬
    warmth = round(random.uniform(1.0, 5.0), 1)
    breathability = round(random.uniform(1.0, 5.0), 1)
    water_res = round(random.uniform(1.0, 5.0), 1)
    precip_prob = random.randint(0, 100)
    fabric_clo_map = {1: 0.15, 2: 0.4, 3: 0.7, 4: 1.5, 5: 2.8}
    base_clo = get_clo_from_warmth(warmth)
    fabric_clo = base_clo * random.uniform(0.95, 1.05)  # ë³´ì˜¨ë ¥ Â±10% ë³€ë™

    # ë¡œì§ íŒë³„
    raw_pmv = calculate_pmv_standard(temp, temp, wind_speed, humidity, DEFAULT_MET, fabric_clo)

    # ì´ìƒì¹˜ ì œê±°
    if raw_pmv == 999:
        score = 10  # ê³„ì‚° ë¶ˆê°€ ì‹œ ê¸°ë³¸ ì ìˆ˜
    else:
        # PMV ë³´ì • ë° ê±°ë¦¬ ê³„ì‚°
        final_pmv = get_corrected_pmv(raw_pmv, wind_speed)
        dist = abs(final_pmv)  # 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¾Œì 

        # =================================================================
        # ğŸ¯ [Part 1] ì—´ì  ì¾Œì ì„± ì ìˆ˜ (Max 60ì )
        # =================================================================
        # ì •ê·œë¶„í¬ ê³¡ì„ (Bell Curve) ì‚¬ìš©: 0ì ì¼ ë•Œ 60ì  ë§Œì , ë©€ì–´ì§ˆìˆ˜ë¡ ë¶€ë“œëŸ½ê²Œ ê°ì†Œ
        thermal_score = 60 * math.exp(-0.3 * (dist ** 2))

        # [ë³´ì •] ë”ìš´ ê²ƒ(ì–‘ìˆ˜)ì€ ì¶”ìš´ ê²ƒë³´ë‹¤ ì°¸ê¸° í˜ë“œë¯€ë¡œ ì ìˆ˜ë¥¼ ë” ê¹ìŒ
        if final_pmv > 0:
            thermal_score *= 0.8

        # ë„ˆë¬´ ê·¹ë‹¨ì ì¸ ì˜¨ë„(PMV > 3.5)ëŠ” ì¾Œì  ì ìˆ˜ 0ì  ì²˜ë¦¬
        if dist > 3.5:
            thermal_score = 0

        # =================================================================
        # ğŸ›¡ï¸ [Part 2] ê¸°ëŠ¥ì„±/ë³´í˜¸ ì ìˆ˜ (Max 25ì )
        # =================================================================
        protection_score = 25  # ê¸°ë³¸ ë§Œì  ì‹œì‘

        # ë¹„ ì˜¬ í™•ë¥ ì´ 40% ì´ìƒì¼ ë•Œ
        if precip_prob > 40:
            if water_res == 1.5:  # ì™„ì „ ë¹„ë°©ìˆ˜ (ë¦°ë„¨, ì–‡ì€ ë©´)
                protection_score = 5  # í¬ê²Œ ê¹ì§€ë§Œ 0ì ì€ ì•„ë‹˜
            elif water_res == 2.5:  # ì•½í•œ ë°©ìˆ˜ (ìš¸, ë°ë‹˜)
                protection_score = 15  # ì ë‹¹íˆ ê¹ìŒ
            # water_res 3 ì´ìƒì€ ë§Œì (25ì ) ìœ ì§€

        # =================================================================
        # ğŸƒ [Part 3] ìƒí™©/ì¾Œì  ì ìˆ˜ (Max 15ì )
        # =================================================================
        comfort_score = 15  # ê¸°ë³¸ ë§Œì  ì‹œì‘

        # ìŠµë„ê°€ ë†’ì€ë°(80%+) í†µê¸°ì„±ì´ ë‚˜ì¨
        if humidity > 80 and breathability < 2.5:
            comfort_score -= 5

        # ì¼êµì°¨ê°€ í°ë°(10ë„+) ì˜·ì´ ë„ˆë¬´ ì–‡ê±°ë‚˜ ë‘êº¼ì›€
        if temp_diff >= 10:
            if warmth == 1: comfort_score -= 5  # ë°¤ì— ì¶”ì›€
            if warmth == 5: comfort_score -= 5  # ë‚®ì— ë”ì›€

        # =================================================================
        # ğŸ”¥ [Part 4] ì ˆëŒ€ ê·œì¹™ (Hard Veto) - ê³±í•˜ê¸° ë°©ì‹
        # =================================================================
        multiplier = 1.0

        # ê²¨ìš¸(5ë„ ë¯¸ë§Œ)ì— ì–‡ì€ ì˜·(Warmth 1~2) ì ˆëŒ€ ê¸ˆì§€
        if temp < 5.0 and warmth <= 2.5:
            multiplier = 0.0

        # ì—¬ë¦„(28ë„ ì´ìƒ)ì— ë‘êº¼ìš´ ì˜·(Warmth 4~5) ì ˆëŒ€ ê¸ˆì§€
        if temp > 28.0 and warmth >= 3.5:
            multiplier = 0.0

        # ìµœì¢… í•©ì‚°
        score = (thermal_score + protection_score + comfort_score) * multiplier

        # 5. ì ìˆ˜ ì •ë¦¬ ë° ë°ì´í„° ì¶”ê°€
    score += random.uniform(-3, 3)  # ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€
    score = max(0, min(100, score))  # 0~100 ì‚¬ì´ë¡œ ê³ ì •

    # ë…¸ì´ì¦ˆê°€ ì„ì¸ Feature ìƒì„±
    noise_temp = temp + random.normalvariate(0, 0.5)
    noise_hum = humidity + random.normalvariate(0, 2.0)
    data.append([noise_temp, noise_hum, precip_prob, wind_speed, temp_diff, warmth, breathability, water_res, score])

# DataFrame ìƒì„±
columns = ['temp', 'humidity', 'precip_prob', 'wind_speed', 'temp_diff', 'warmth', 'breathability', 'water_res',
           'score']
df = pd.DataFrame(data, columns=columns)

X = df.drop('score', axis=1)
y = df['score']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- 4. Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ---
best_params = {
    'n_estimators': 557,
    'learning_rate': 0.016686714196678172,
    'num_leaves': 50,
    'max_depth': 9,
    'min_child_samples': 50,
    'objective': 'regression',
    'metric': 'rmse',
    'random_state': 42,
    'n_jobs': 4,
    'verbose': -1
}

print(f"ğŸš€ LightGBM Final í•™ìŠµ ì‹œì‘ (Best Params ì ìš©)")

model = LGBMRegressor(**best_params)
model.fit(X_train, y_train)

# --- 5. ìµœì¢… í‰ê°€ ---
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("="*40)
print(f"ğŸ† ìµœì¢… ëª¨ë¸ í‰ê·  ì˜¤ì°¨(MAE): {mae:.2f}ì ")
print(f"âœ… ê²°ì • ê³„ìˆ˜(R2) : {r2:.4f}")
print("="*40)


# êµì°¨ ê²€ì¦
cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')
# neg_maeëŠ” ìŒìˆ˜ê°’ì´ë¯€ë¡œ ì–‘ìˆ˜ë¡œ ë³€í™˜
mae_scores = -cv_scores
print(f"âœ… êµì°¨ ê²€ì¦ í‰ê·  ì˜¤ì°¨(MAE): {mae_scores.mean():.2f}ì  (Â±{mae_scores.std():.2f})")

# --- 6. íŠ¹ì„± ì¤‘ìš”ë„ (Feature Importance) ---
importances = model.feature_importances_
feature_names = X.columns
sorted_idx = np.argsort(importances)[::-1]

print("-" * 30)
print("ğŸ” PMV ëª¨ë¸ì´ ì¤‘ìš”í•˜ê²Œ ìƒê°í•œ ìš”ì†Œ (Top 3):")
for i in range(3):
    print(f"{i + 1}ìœ„: {feature_names[sorted_idx[i]]} (Score: {importances[sorted_idx[i]]:.1f})")
print("-" * 30)

# --- 7. í•™ìŠµ ê³¡ì„  (Scoring ë²„ê·¸ ìˆ˜ì •ë¨) ---
print("\nğŸ–¼ï¸ í•™ìŠµ ê³¡ì„ (Learning Curve) ìƒì„± ì¤‘...")
train_sizes, train_scores, valid_scores = learning_curve(
    model, X, y, cv=5,
    scoring='neg_mean_absolute_error', # [ìˆ˜ì •ë¨] accuracy -> neg_mae
    train_sizes=np.linspace(0.1, 1.0, 5)
)

# ìŒìˆ˜ MAEë¥¼ ì–‘ìˆ˜ë¡œ ë³€í™˜
train_mean = -np.mean(train_scores, axis=1)
valid_mean = -np.mean(valid_scores, axis=1)

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_mean, 'o-', color="purple", label="Training Error (MAE)")
plt.plot(train_sizes, valid_mean, 'o-', color="teal", label="Validation Error (MAE)")
plt.title("Learning Curve (Regression MAE) - Lower is Better") # ì œëª© ìˆ˜ì •
plt.xlabel("Training Examples")
plt.ylabel("Mean Absolute Error") # ì¶• ì´ë¦„ ìˆ˜ì •
plt.legend(loc="best")
plt.grid()

# ì €ì¥
current_dir = os.path.dirname(os.path.abspath(__file__))
artifacts_dir = os.path.join(current_dir, "..", "artifacts")
os.makedirs(artifacts_dir, exist_ok=True)
save_img_path = os.path.join(artifacts_dir, "learning_curve_regression.png")
plt.savefig(save_img_path)
print(f"   -> ì‹œê°í™” ì €ì¥ë¨: {save_img_path}")

# ëª¨ë¸ ì €ì¥
save_model_path = os.path.join(artifacts_dir, "weather_material_pmv.pkl")
joblib.dump(model, save_model_path)
print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_model_path}")